{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b36b5d",
   "metadata": {},
   "source": [
    "#  Age Determination using Cervical Spine X-ray Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8baec0e",
   "metadata": {},
   "source": [
    "The notebook presents a machine learning pipeline aimed at predicting the ages of patients using cervical spine X-ray images. This task is a regression problem, as the target variable is continuous (age). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e947cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a78946",
   "metadata": {},
   "source": [
    "#### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8415a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-14-F.jpg',\n",
       " '10-15-M.jpg',\n",
       " '11-13-F.jpg',\n",
       " '12-14-F.jpg',\n",
       " '13-10-M.jpg',\n",
       " '14-14-F.jpg',\n",
       " '15-12-M.jpg',\n",
       " '16-13-M.jpg',\n",
       " '17-13-F.jpg',\n",
       " '18-12-M.jpg',\n",
       " '19-15-M.jpg',\n",
       " '2-10-M.jpg',\n",
       " '20-17-M.jpg',\n",
       " '21-13-F.jpg',\n",
       " '22-13-M.jpg',\n",
       " '23-15-F.jpg',\n",
       " '24-19-F.jpg',\n",
       " '25-14-F.jpg',\n",
       " '26-16-F.jpg',\n",
       " '27-14-F.jpg',\n",
       " '28-11-M.jpg',\n",
       " '29-16-M.jpg',\n",
       " '3-12-M.jpg',\n",
       " '30-12-M.jpg',\n",
       " '4-15-M.jpg',\n",
       " '5-13-O.jpg',\n",
       " '6-16-M.jpg',\n",
       " '7-12-M.jpg',\n",
       " '8-16-M.jpg',\n",
       " '9-10-F.jpg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_images = os.listdir(r\"C:\\Users\\Asus\\Desktop\\Cervical_Dataset\\Cervical_Data\\Final\")\n",
    "ls_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1a7cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for i in ls_images:\n",
    "    image_path = os.path.join(r\"C:\\Users\\Asus\\Desktop\\Cervical_Dataset\\Cervical_Data\\Final\", i)\n",
    "    image = cv2.imread(image_path)\n",
    "    image = image/255.0\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c154e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfd2101",
   "metadata": {},
   "source": [
    "#### All images loaded successfully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80803fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_labels = [filename.split(\"-\")[1] for filename in ls_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd3a7b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14', '15', '13', '14', '10']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "688e2e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_labels = [int(i) for i in image_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8fda4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images), len(image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c1f68ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 15, 13, 14, 10, 14, 12, 13, 13, 12, 15, 10, 17, 13, 13, 15, 19, 14, 16, 14, 11, 16, 12, 12, 15, 13, 16, 12, 16, 10]\n"
     ]
    }
   ],
   "source": [
    "print(image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcb0a22c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3934200\n",
      "(1660, 790, 3)\n",
      "---------------------------------\n",
      "4854168\n",
      "(1782, 908, 3)\n",
      "---------------------------------\n",
      "4004934\n",
      "(1634, 817, 3)\n",
      "---------------------------------\n",
      "3269619\n",
      "(1459, 747, 3)\n",
      "---------------------------------\n",
      "3949974\n",
      "(1334, 987, 3)\n",
      "---------------------------------\n",
      "4588980\n",
      "(1870, 818, 3)\n",
      "---------------------------------\n",
      "2969484\n",
      "(1219, 812, 3)\n",
      "---------------------------------\n",
      "8923500\n",
      "(1983, 1500, 3)\n",
      "---------------------------------\n",
      "7359195\n",
      "(1909, 1285, 3)\n",
      "---------------------------------\n",
      "7020000\n",
      "(2000, 1170, 3)\n",
      "---------------------------------\n",
      "8003160\n",
      "(2068, 1290, 3)\n",
      "---------------------------------\n",
      "3499881\n",
      "(1529, 763, 3)\n",
      "---------------------------------\n",
      "7180992\n",
      "(1918, 1248, 3)\n",
      "---------------------------------\n",
      "8264304\n",
      "(1979, 1392, 3)\n",
      "---------------------------------\n",
      "7690464\n",
      "(1978, 1296, 3)\n",
      "---------------------------------\n",
      "7557699\n",
      "(2017, 1249, 3)\n",
      "---------------------------------\n",
      "8824500\n",
      "(1961, 1500, 3)\n",
      "---------------------------------\n",
      "3527433\n",
      "(1533, 767, 3)\n",
      "---------------------------------\n",
      "5222349\n",
      "(1819, 957, 3)\n",
      "---------------------------------\n",
      "6787890\n",
      "(1895, 1194, 3)\n",
      "---------------------------------\n",
      "4232820\n",
      "(1501, 940, 3)\n",
      "---------------------------------\n",
      "5123763\n",
      "(1741, 981, 3)\n",
      "---------------------------------\n",
      "3811500\n",
      "(1500, 847, 3)\n",
      "---------------------------------\n",
      "2875320\n",
      "(1304, 735, 3)\n",
      "---------------------------------\n",
      "4237200\n",
      "(1712, 825, 3)\n",
      "---------------------------------\n",
      "3996954\n",
      "(1482, 899, 3)\n",
      "---------------------------------\n",
      "4595400\n",
      "(1656, 925, 3)\n",
      "---------------------------------\n",
      "3685890\n",
      "(1454, 845, 3)\n",
      "---------------------------------\n",
      "3016818\n",
      "(1041, 966, 3)\n",
      "---------------------------------\n",
      "2810586\n",
      "(1327, 706, 3)\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in images:\n",
    "    print(i.size)\n",
    "    print(i.shape)\n",
    "    print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dc05636",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous size - 3934200\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 4854168\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 4004934\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 3269619\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 3949974\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 4588980\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 2969484\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 8923500\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 7359195\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 7020000\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 8003160\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 3499881\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 7180992\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 8264304\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 7690464\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 7557699\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 8824500\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 3527433\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 5222349\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 6787890\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 4232820\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 5123763\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 3811500\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 2875320\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 4237200\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 3996954\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 4595400\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 3685890\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 3016818\n",
      "New size - 16384\n",
      "----------------\n",
      "Previous size - 2810586\n",
      "New size - 16384\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "resized_images = []\n",
    "\n",
    "for j in images:\n",
    "    k = np.resize(j, 16384)\n",
    "    resized_images.append(k)\n",
    "    print(f\"Previous size -\", j.size)\n",
    "    print(f\"New size -\", k.size)\n",
    "    print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7ba8ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb612812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1660, 790, 3)\n",
      "---------------------------------\n",
      "(1782, 908, 3)\n",
      "---------------------------------\n",
      "(1634, 817, 3)\n",
      "---------------------------------\n",
      "(1459, 747, 3)\n",
      "---------------------------------\n",
      "(1334, 987, 3)\n",
      "---------------------------------\n",
      "(1870, 818, 3)\n",
      "---------------------------------\n",
      "(1219, 812, 3)\n",
      "---------------------------------\n",
      "(1983, 1500, 3)\n",
      "---------------------------------\n",
      "(1909, 1285, 3)\n",
      "---------------------------------\n",
      "(2000, 1170, 3)\n",
      "---------------------------------\n",
      "(2068, 1290, 3)\n",
      "---------------------------------\n",
      "(1529, 763, 3)\n",
      "---------------------------------\n",
      "(1918, 1248, 3)\n",
      "---------------------------------\n",
      "(1979, 1392, 3)\n",
      "---------------------------------\n",
      "(1978, 1296, 3)\n",
      "---------------------------------\n",
      "(2017, 1249, 3)\n",
      "---------------------------------\n",
      "(1961, 1500, 3)\n",
      "---------------------------------\n",
      "(1533, 767, 3)\n",
      "---------------------------------\n",
      "(1819, 957, 3)\n",
      "---------------------------------\n",
      "(1895, 1194, 3)\n",
      "---------------------------------\n",
      "(1501, 940, 3)\n",
      "---------------------------------\n",
      "(1741, 981, 3)\n",
      "---------------------------------\n",
      "(1500, 847, 3)\n",
      "---------------------------------\n",
      "(1304, 735, 3)\n",
      "---------------------------------\n",
      "(1712, 825, 3)\n",
      "---------------------------------\n",
      "(1482, 899, 3)\n",
      "---------------------------------\n",
      "(1656, 925, 3)\n",
      "---------------------------------\n",
      "(1454, 845, 3)\n",
      "---------------------------------\n",
      "(1041, 966, 3)\n",
      "---------------------------------\n",
      "(1327, 706, 3)\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in images:\n",
    "    print(i.shape)\n",
    "    print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "327ad24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shapes = []\n",
    "\n",
    "for i in images:\n",
    "    image_shapes.append(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d906bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1660, 790, 3),\n",
       " (1782, 908, 3),\n",
       " (1634, 817, 3),\n",
       " (1459, 747, 3),\n",
       " (1334, 987, 3),\n",
       " (1870, 818, 3),\n",
       " (1219, 812, 3),\n",
       " (1983, 1500, 3),\n",
       " (1909, 1285, 3),\n",
       " (2000, 1170, 3),\n",
       " (2068, 1290, 3),\n",
       " (1529, 763, 3),\n",
       " (1918, 1248, 3),\n",
       " (1979, 1392, 3),\n",
       " (1978, 1296, 3),\n",
       " (2017, 1249, 3),\n",
       " (1961, 1500, 3),\n",
       " (1533, 767, 3),\n",
       " (1819, 957, 3),\n",
       " (1895, 1194, 3),\n",
       " (1501, 940, 3),\n",
       " (1741, 981, 3),\n",
       " (1500, 847, 3),\n",
       " (1304, 735, 3),\n",
       " (1712, 825, 3),\n",
       " (1482, 899, 3),\n",
       " (1656, 925, 3),\n",
       " (1454, 845, 3),\n",
       " (1041, 966, 3),\n",
       " (1327, 706, 3)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63923ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_images = []\n",
    "\n",
    "for m in resized_images:\n",
    "    k = np.reshape(m, (128, 128))\n",
    "    reshaped_images.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "551c6da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape - (1660, 790, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1782, 908, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1634, 817, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1459, 747, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1334, 987, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1870, 818, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1219, 812, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1983, 1500, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1909, 1285, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (2000, 1170, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (2068, 1290, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1529, 763, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1918, 1248, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1979, 1392, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1978, 1296, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (2017, 1249, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1961, 1500, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1533, 767, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1819, 957, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1895, 1194, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1501, 940, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1741, 981, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1500, 847, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1304, 735, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1712, 825, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1482, 899, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1656, 925, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1454, 845, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1041, 966, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n",
      "Previous shape - (1327, 706, 3)\n",
      "New shape - (128, 128)\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 30):\n",
    "    print(f\"Previous shape -\", image_shapes[i])\n",
    "    print(f\"New shape -\", k.shape)\n",
    "    print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d15d669",
   "metadata": {},
   "outputs": [],
   "source": [
    "cervical_spine_images = np.array(reshaped_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "579cab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = np.array(image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b94d0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "795b7e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_Test_Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cervical_spine_images, ages, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2703868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1)  # Single output for regression\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eca39bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['r2_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbc2ce8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292ms/step - loss: 0.7859 - r2_score: 0.8606 - val_loss: 5.3856 - val_r2_score: -4.1785\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.6463 - r2_score: 0.8971 - val_loss: 5.5418 - val_r2_score: -4.3287\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.7463 - r2_score: 0.8559 - val_loss: 5.7319 - val_r2_score: -4.5114\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 0.7200 - r2_score: 0.8881 - val_loss: 5.9840 - val_r2_score: -4.7538\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.6566 - r2_score: 0.8983 - val_loss: 6.2572 - val_r2_score: -5.0166\n",
      "Epoch 6/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.5371 - r2_score: 0.9069 - val_loss: 6.6138 - val_r2_score: -5.3594\n",
      "Epoch 7/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.6950 - r2_score: 0.8910 - val_loss: 6.9267 - val_r2_score: -5.6603\n",
      "Epoch 8/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.8094 - r2_score: 0.8528 - val_loss: 6.7266 - val_r2_score: -5.4678\n",
      "Epoch 9/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245ms/step - loss: 0.7197 - r2_score: 0.8813 - val_loss: 6.4237 - val_r2_score: -5.1766\n",
      "Epoch 10/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 0.6765 - r2_score: 0.8865 - val_loss: 6.3225 - val_r2_score: -5.0794\n",
      "Epoch 11/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - loss: 0.6562 - r2_score: 0.8969 - val_loss: 6.2765 - val_r2_score: -5.0351\n",
      "Epoch 12/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.4465 - r2_score: 0.9278 - val_loss: 6.0682 - val_r2_score: -4.8348\n",
      "Epoch 13/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.5482 - r2_score: 0.9140 - val_loss: 5.7572 - val_r2_score: -4.5358\n",
      "Epoch 14/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.6080 - r2_score: 0.8960 - val_loss: 5.6466 - val_r2_score: -4.4294\n",
      "Epoch 15/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.7302 - r2_score: 0.8813 - val_loss: 5.6818 - val_r2_score: -4.4632\n",
      "Epoch 16/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.7189 - r2_score: 0.8809 - val_loss: 5.8217 - val_r2_score: -4.5978\n",
      "Epoch 17/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.6061 - r2_score: 0.9021 - val_loss: 6.1291 - val_r2_score: -4.8933\n",
      "Epoch 18/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237ms/step - loss: 0.5189 - r2_score: 0.9173 - val_loss: 6.3854 - val_r2_score: -5.1398\n",
      "Epoch 19/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.4025 - r2_score: 0.9319 - val_loss: 6.3642 - val_r2_score: -5.1194\n",
      "Epoch 20/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.5273 - r2_score: 0.9004 - val_loss: 6.2789 - val_r2_score: -5.0374\n",
      "Epoch 21/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.5381 - r2_score: 0.9076 - val_loss: 6.2805 - val_r2_score: -5.0389\n",
      "Epoch 22/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.4924 - r2_score: 0.9181 - val_loss: 6.4080 - val_r2_score: -5.1615\n",
      "Epoch 23/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.4963 - r2_score: 0.9199 - val_loss: 6.4529 - val_r2_score: -5.2047\n",
      "Epoch 24/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.5049 - r2_score: 0.9106 - val_loss: 6.3460 - val_r2_score: -5.1019\n",
      "Epoch 25/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.4789 - r2_score: 0.9236 - val_loss: 6.3412 - val_r2_score: -5.0973\n",
      "Epoch 26/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.4288 - r2_score: 0.9279 - val_loss: 6.5065 - val_r2_score: -5.2563\n",
      "Epoch 27/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 251ms/step - loss: 0.4547 - r2_score: 0.9286 - val_loss: 6.8071 - val_r2_score: -5.5453\n",
      "Epoch 28/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.4851 - r2_score: 0.9219 - val_loss: 6.9313 - val_r2_score: -5.6647\n",
      "Epoch 29/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.5137 - r2_score: 0.9152 - val_loss: 6.7701 - val_r2_score: -5.5097\n",
      "Epoch 30/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.3258 - r2_score: 0.9470 - val_loss: 6.5097 - val_r2_score: -5.2593\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split = 0.2, epochs=30, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a9edb12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 93.04%\n"
     ]
    }
   ],
   "source": [
    "print(f\"R^2 Score: {history.history['r2_score'][-1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2627d5",
   "metadata": {},
   "source": [
    "This model achieved R^2 Score of 93.04%.\n",
    "\n",
    "- 94% of the variance in patient ages was successfully explained by the features extracted from cervical spine X-ray images.\n",
    "\n",
    "- The remaining 6% of the variability is due to factors not captured by the model, such as noise in the data, inherent variability in the biological processes, or potential limitations in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b97f9",
   "metadata": {},
   "source": [
    "### Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46dea2b",
   "metadata": {},
   "source": [
    "This project lays a solid foundation for cervical bone age determination using deep learning. It demonstrates effective data preprocessing, the use of CNNs for image regression, and a systematic approach to training and validation. It can serve as a stepping stone for more complex medical imaging projects and pave the way for developing clinical-grade predictive systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
